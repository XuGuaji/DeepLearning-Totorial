{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92f71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf402f5",
   "metadata": {},
   "source": [
    "## 获取和读取数据\n",
    "这里继续使用Fashion-MNIST数据集。我们将使用多层感知机对图像进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4796c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71cb5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a15e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features,labels = mnist_train[0]\n",
    "features.size(),labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665766c",
   "metadata": {},
   "source": [
    "## 定义模型参数\n",
    "Fashion-MNIST数据集中图像形状为 28×28\n",
    "28×28，类别数为10。本节中我们依然使用长度为 28×28=784\n",
    "28×28=784 的向量表示每一张图像。因此，输入个数为784，输出个数为10。实验中，我们设超参数隐藏单元个数为256。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0572dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_outputs,num_hiddens = 784,10,256\n",
    "\n",
    "W1 = torch.tensor(np.random.normal(0,0.01,(num_inputs,num_hiddens)),dtype=torch.float)\n",
    "b1 = torch.zeros(num_hiddens,dtype=torch.float)\n",
    "W2 = torch.tensor(np.random.normal(0,0.01,(num_hiddens,num_outputs)),dtype=torch.float)\n",
    "b2 = torch.zeros(num_outputs,dtype=torch.float)\n",
    "\n",
    "params = [W1,b1,W2,b2]\n",
    "for param in params:\n",
    "    param.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9656d",
   "metadata": {},
   "source": [
    "## 定义激活函数\n",
    "这里我们使用基础的`max`函数来实现ReLU，而非直接调用`relu`函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b11cce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return torch.max(input=X,other=torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54213c8",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "同softmax回归一样，我们通过`view`函数将每张原始图像改成长度为`num_inputs`的向量。然后我们实现上一节中多层感知机的计算表达式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ca5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = X.view((-1,num_inputs))\n",
    "    H = relu(torch.matmul(X,W1)+b1)\n",
    "    return torch.matmul(H,W2) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba415ec6",
   "metadata": {},
   "source": [
    "## 定义损失函数\n",
    "为了得到更好的数值稳定性，我们直接使用PyTorch提供的包括softmax运算和交叉熵损失计算的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd42c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c947592",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''计算分类准确率'''\n",
    "def accuracy(y_hat,y):\n",
    "    return (y_hat.argmax(dim=1)==y).float().mean().item()\n",
    "\n",
    "'''评价模型net在数据集data_iter上的准确率'''\n",
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n = 0.0,0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "'''定义优化算法'''\n",
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e32d1c",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "我们在这里设超参数迭代周期数为5，学习率为100.0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cb7c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss 0.0030,train_acc 0.712,test acc 0.741\n",
      "epoch 2,loss 0.0019,train_acc 0.823,test acc 0.793\n",
      "epoch 3,loss 0.0017,train_acc 0.844,test acc 0.770\n",
      "epoch 4,loss 0.0016,train_acc 0.855,test acc 0.821\n",
      "epoch 5,loss 0.0014,train_acc 0.865,test acc 0.834\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 5, 100\n",
    "\n",
    "def train_(net,train_iter,test_iter,loss,num_epochs,batch_size,\n",
    "                  params = None, lr = None, optimizer = None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n = .0,.0,0\n",
    "        for X,y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            # X: 256 * 784\n",
    "            # y_hat: 256 * 10\n",
    "            # y: 256 * 1\n",
    "            l = loss(y_hat,y).sum()\n",
    "            \n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params,lr,batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "        \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1)==y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print(\"epoch %d,loss %.4f,train_acc %.3f,test acc %.3f\"\n",
    "              %(epoch+1,train_l_sum / n,train_acc_sum / n,test_acc))\n",
    "\n",
    "train_(net,train_iter,test_iter,loss,num_epochs,batch_size,\n",
    "              params,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8ac51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
