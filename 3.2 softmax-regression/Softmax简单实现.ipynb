{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae10633a",
   "metadata": {},
   "source": [
    "在介绍softmax回归的实现前我们先引入一个多类图像分类数据集。它将在后面的章节中被多次使用，以方便我们观察比较算法之间在模型精度和计算效率上的区别。图像分类数据集中最常用的是手写数字识别数据集MNIST[1]。但大部分模型在MNIST上的分类精度都超过了95%。为了更直观地观察算法之间的差异，我们将使用一个图像内容更加复杂的数据集Fashion-MNIST[2]（这个数据集也比较小，只有几十M，没有GPU的电脑也能吃得消"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e59a81",
   "metadata": {},
   "source": [
    "本节我们将使用torchvision包，它是服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型。torchvision主要由以下几部分构成：\n",
    "\n",
    "+ torchvision.datasets: 一些加载数据的函数及常用的数据集接口；\n",
    "+ torchvision.models: 包含常用的模型结构（含预训练模型），例如+AlexNet、VGG、ResNet等；\n",
    "+ torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；\n",
    "+ torchvision.utils: 其他的一些有用的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d94b94",
   "metadata": {},
   "source": [
    "## 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a87c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4435eb",
   "metadata": {},
   "source": [
    "下面，我们通过torchvision的torchvision.datasets来下载这个数据集。第一次调用时会自动从网上获取数据。我们通过参数train来指定获取训练数据集或测试数据集（testing data set）。测试数据集也叫测试集（testing set），只用来评价模型的表现，并不用来训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e2b3c",
   "metadata": {},
   "source": [
    "另外我们还指定了参数transform = transforms.ToTensor()使所有数据转换为Tensor，如果不进行转换则返回的是PIL图片。\n",
    "\n",
    "transforms.ToTensor()将尺寸为 (H x W x C) 且数据位于[0, 255]的PIL图片\n",
    "\n",
    "或者数据类型为np.uint8的NumPy数组转换为尺寸为(C x H x W)且数据类型为torch.float32且位于[0.0, 1.0]的Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f774f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c28ea",
   "metadata": {},
   "source": [
    "上面的mnist_train和mnist_test都是torch.utils.data.Dataset的子类，所以我们可以用len()来获取该数据集的大小，还可以用下标来获取具体的一个样本。训练集中和测试集中的每个类别的图像数分别为6,000和1,000。因为有10个类别，所以训练集和测试集的样本数分别为60,000和10,000。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc2d482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "print(type(mnist_train))\n",
    "print(len(mnist_train), len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99b2f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "feature, label = mnist_train[0]\n",
    "print(feature.shape, label)  # Channel x Height x Width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae85462",
   "metadata": {},
   "source": [
    "变量feature对应高和宽均为28像素的图像。由于我们使用了transforms.ToTensor()，所以每个像素的数值为[0.0, 1.0]的32位浮点数。需要注意的是，feature的尺寸是 (C x H x W) 的，而不是 (H x W x C)。第一维是通道数，因为数据集中是灰度图像，所以通道数为1。后面两维分别是图像的高和宽。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eba739",
   "metadata": {},
   "source": [
    "Fashion-MNIST中一共包括了10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。以下函数可以将数值标签转成相应的文本标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d6e1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39a951",
   "metadata": {},
   "source": [
    "下面定义一个可以在一行里画出多张图像和对应标签的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1db8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    d2l.use_svg_display()\n",
    "    # 这里的_表示我们忽略（不使用）的变量\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
